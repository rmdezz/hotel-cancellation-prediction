{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "461514f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m X = df.drop(columns=cfg[\u001b[33m\"\u001b[39m\u001b[33mid_columns\u001b[39m\u001b[33m\"\u001b[39m] + [cfg[\u001b[33m\"\u001b[39m\u001b[33mtarget_column\u001b[39m\u001b[33m\"\u001b[39m]])\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# ── 4. crear pipeline y evaluar ───────────────────────────────\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m pipe = \u001b[43mmake_full_model_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m oof = np.zeros(\u001b[38;5;28mlen\u001b[39m(X), dtype=\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     37\u001b[39m skf = StratifiedKFold(\u001b[32m5\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/hotel-cancellation-prediction/src/full_model_pipeline.py:107\u001b[39m, in \u001b[36mmake_full_model_pipeline\u001b[39m\u001b[34m(cfg_path)\u001b[39m\n\u001b[32m     90\u001b[39m     encoder = ColumnTransformer(\n\u001b[32m     91\u001b[39m         transformers=[\n\u001b[32m     92\u001b[39m             (\u001b[33m'\u001b[39m\u001b[33mtarget_enc\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m         remainder=\u001b[33m'\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    102\u001b[39m     )\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m enc_method == \u001b[33m'\u001b[39m\u001b[33monehot\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    104\u001b[39m     encoder = ColumnTransformer(\n\u001b[32m    105\u001b[39m         transformers=[\n\u001b[32m    106\u001b[39m             (\u001b[33m'\u001b[39m\u001b[33monehot_enc\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m              \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mignore\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m                 \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    110\u001b[39m \u001b[43m             \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    111\u001b[39m              make_column_selector(dtype_include=[\u001b[33m'\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    112\u001b[39m             )\n\u001b[32m    113\u001b[39m         ],\n\u001b[32m    114\u001b[39m         remainder=\u001b[33m'\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    115\u001b[39m     )\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown encoding method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menc_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
     ]
    }
   ],
   "source": [
    "# ── 1. poner la raíz en sys.path ──────────────────────────────\n",
    "import os, sys\n",
    "ROOT = os.path.abspath(os.path.join(\"..\"))\n",
    "sys.path.insert(0, ROOT)\n",
    "\n",
    "import numpy as np\n",
    "import yaml, pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from src.full_model_pipeline import make_full_model_pipeline\n",
    "from src.utils import load_config\n",
    "\n",
    "# ── 2. cargar config ──────────────────────────────────────────\n",
    "CONFIG_PATH = os.path.join(ROOT, \"configs\", \"base_config.yaml\")\n",
    "cfg = load_config(CONFIG_PATH)\n",
    "\n",
    "# ── 3. leer CSV con ruta absoluta ────────────────────────────\n",
    "train_path = os.path.join(ROOT, cfg[\"data_raw_path\"], cfg[\"train_file\"])\n",
    "df = pd.read_csv(train_path)\n",
    "\n",
    "# ── 3.1 mapear target de strings a 0/1 ───────────────────────\n",
    "mapping = {\n",
    "    \"Cancelada\":     1,\n",
    "    \"No Cancelada\":  0\n",
    "}\n",
    "y = df[cfg[\"target_column\"]].map(mapping)\n",
    "if y.isna().any():\n",
    "    raise ValueError(\"Se detectaron valores de target fuera del mapping: \"\n",
    "                     f\"{y[y.isna()].unique()}\")\n",
    "\n",
    "X = df.drop(columns=cfg[\"id_columns\"] + [cfg[\"target_column\"]])\n",
    "\n",
    "# ── 4. crear pipeline y evaluar ───────────────────────────────\n",
    "pipe = make_full_model_pipeline(CONFIG_PATH)\n",
    "\n",
    "oof = np.zeros(len(X), dtype=int)\n",
    "skf = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "\n",
    "for tr_idx, va_idx in skf.split(X, y):\n",
    "    pipe.fit(X.iloc[tr_idx], y.iloc[tr_idx])\n",
    "    oof[va_idx] = pipe.predict(X.iloc[va_idx])\n",
    "\n",
    "print(\"Weighted F1 OOF:\", f1_score(y, oof, average=\"weighted\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7e4148",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ricardomelendez/Documents/hotel-cancellation-prediction/configs/best_config_optuna.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# ── 2. cargar la MEJOR config encontrada por Optuna ────────────\u001b[39;00m\n\u001b[32m     16\u001b[39m BEST_CONFIG_PATH = os.path.join(ROOT, \u001b[33m\"\u001b[39m\u001b[33mconfigs\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbest_config_optuna.yaml\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# <- USA EL NUEVO ARCHIVO\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m cfg_best = \u001b[43mload_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBEST_CONFIG_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mConfiguración Optimizada cargada.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# ── 3. leer CSV y preparar datos (igual que antes) ──────────────\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/hotel-cancellation-prediction/src/utils.py:8\u001b[39m, in \u001b[36mload_config\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_config\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m      7\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Carga un archivo YAML de configuración.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      9\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m yaml.safe_load(f)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/ricardomelendez/Documents/hotel-cancellation-prediction/configs/best_config_optuna.yaml'"
     ]
    }
   ],
   "source": [
    "# ── 1. poner la raíz en sys.path ──────────────────────────────\n",
    "import os, sys\n",
    "ROOT = os.path.abspath(os.path.join(\"..\")) # Ajusta si es necesario\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)\n",
    "\n",
    "import numpy as np\n",
    "import yaml, pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from src.full_model_pipeline import make_full_model_pipeline # Asumo que toma dict cfg\n",
    "from src.utils import load_config\n",
    "import copy\n",
    "\n",
    "# ── 2. cargar la MEJOR config encontrada por Optuna ────────────\n",
    "BEST_CONFIG_PATH = os.path.join(ROOT, \"configs\", \"best_config_optuna_100.yaml\") # <- USA EL NUEVO ARCHIVO\n",
    "cfg_best = load_config(BEST_CONFIG_PATH)\n",
    "print(\"Configuración Optimizada cargada.\")\n",
    "\n",
    "# ── 3. leer CSV y preparar datos (igual que antes) ──────────────\n",
    "train_path = os.path.join(ROOT, cfg_best[\"data_raw_path\"], cfg_best[\"train_file\"])\n",
    "df_train_full = pd.read_csv(train_path)\n",
    "\n",
    "# Mapear target\n",
    "mapping = {\"Cancelada\": 1, \"No Cancelada\": 0}\n",
    "y_true_full = df_train_full[cfg_best[\"target_column\"]].map(mapping)\n",
    "if y_true_full.isna().any():\n",
    "    raise ValueError(f\"Target con NaNs tras mapping: {df_train_full[cfg_best['target_column']][y_true_full.isna()].unique()}\")\n",
    "\n",
    "X_full = df_train_full.drop(columns=cfg_best[\"id_columns\"] + [cfg_best[\"target_column\"]])\n",
    "print(f\"Datos preparados: X_full.shape={X_full.shape}, y_true_full.shape={y_true_full.shape}\")\n",
    "\n",
    "# ── 4. Ejecutar CV UNA VEZ para obtener OOF Probs y Umbral ───────\n",
    "\n",
    "# --- Adaptación de la lógica de run_experiment ---\n",
    "print(\"\\n--- Ejecutando CV con la configuración optimizada para obtener OOF Probs ---\")\n",
    "\n",
    "# --- AJUSTE IMPORTANTE: Pasar config a make_full_model_pipeline ---\n",
    "# Si make_full_model_pipeline espera RUTA:\n",
    "TEMP_CONFIG_PATH_FINAL = os.path.join(ROOT, \"configs\", \"temp_final_config.yaml\")\n",
    "with open(TEMP_CONFIG_PATH_FINAL, 'w') as f:\n",
    "    yaml.dump(cfg_best, f)\n",
    "pipe = make_full_model_pipeline(TEMP_CONFIG_PATH_FINAL)\n",
    "# Si make_full_model_pipeline espera DICT:\n",
    "# pipe = make_full_model_pipeline(cfg_best)\n",
    "# --- Fin del ajuste ---\n",
    "\n",
    "oof_probs = np.zeros(len(X_full)) # Para guardar probabilidades\n",
    "\n",
    "# Usar random_state del config para reproducibilidad de folds\n",
    "skf = StratifiedKFold(n_splits=cfg_best.get(\"cv_n_splits\", 5), \n",
    "                      shuffle=True, \n",
    "                      random_state=cfg_best.get(\"random_seed\", 42))\n",
    "\n",
    "print(\"Iniciando validación cruzada...\")\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_full, y_true_full)):\n",
    "    X_train, X_val = X_full.iloc[tr_idx], X_full.iloc[va_idx]\n",
    "    y_train, y_val = y_true_full.iloc[tr_idx], y_true_full.iloc[va_idx]\n",
    "    \n",
    "    print(f\"  Entrenando Fold {fold+1}/5...\")\n",
    "    # --- Fit Params (Early Stopping - Opcional pero recomendado si n_estimators es alto) ---\n",
    "    # fit_params = {\n",
    "    #     'model__eval_set': [(X_val, y_val)],\n",
    "    #     'model__callbacks': [lgb.early_stopping(50, verbose=False)] # O el callback de pruning si se usa Optuna\n",
    "    # }\n",
    "    # pipe.fit(X_train, y_train, **fit_params)\n",
    "    pipe.fit(X_train, y_train) # Sin early stopping por ahora si no está configurado\n",
    "    # --- Fin Fit Params ---\n",
    "    \n",
    "    # Guardar probabilidades para optimización de umbral\n",
    "    oof_probs[va_idx] = pipe.predict_proba(X_val)[:, 1] # Probabilidad de la clase positiva (1)\n",
    "\n",
    "if os.path.exists(TEMP_CONFIG_PATH_FINAL): # Limpiar config temporal\n",
    "    os.remove(TEMP_CONFIG_PATH_FINAL)\n",
    "    \n",
    "print(\"Validación cruzada completada. Calculando umbral óptimo...\")\n",
    "\n",
    "# Optimización de Umbral sobre todas las predicciones OOF\n",
    "best_f1_weighted = 0\n",
    "best_threshold_weighted = 0.5\n",
    "best_f1_class1 = 0\n",
    "best_threshold_class1 = 0.5\n",
    "positive_class_value = 1 # Asumiendo que \"Cancelada\" es 1\n",
    "\n",
    "for threshold_candidate in np.arange(0.1, 0.9, 0.01):\n",
    "    oof_preds_at_threshold = (oof_probs >= threshold_candidate).astype(int)\n",
    "    \n",
    "    current_f1_weighted = f1_score(y_true_full, oof_preds_at_threshold, average=\"weighted\")\n",
    "    if current_f1_weighted > best_f1_weighted:\n",
    "        best_f1_weighted = current_f1_weighted\n",
    "        best_threshold_weighted = threshold_candidate\n",
    "        \n",
    "    current_f1_class1 = f1_score(y_true_full, oof_preds_at_threshold, pos_label=positive_class_value, average=\"binary\")\n",
    "    if current_f1_class1 > best_f1_class1:\n",
    "        best_f1_class1 = current_f1_class1\n",
    "        best_threshold_class1 = threshold_candidate\n",
    "\n",
    "# --- Resultados Finales ---\n",
    "print(\"\\n--- Resultados con Configuración Optimizada por Optuna ---\")\n",
    "print(f\"Mejor F1 OOF Ponderado (calculado aquí): {best_f1_weighted:.6f}\")\n",
    "print(f\"Umbral Óptimo para F1 Ponderado: {best_threshold_weighted:.2f}\")\n",
    "print(f\"\\nMejor F1 OOF Clase Positiva ('Cancelada'): {best_f1_class1:.6f}\")\n",
    "print(f\"Umbral Óptimo para F1 Clase Positiva: {best_threshold_class1:.2f}\")\n",
    "\n",
    "# Guarda este umbral (probablemente best_threshold_weighted) para usarlo en las predicciones finales\n",
    "final_threshold = best_threshold_weighted \n",
    "print(f\"\\n==> Umbral final a usar para predicciones: {final_threshold:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
